{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-  InclusionCriteria N-Grams Frequencies.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMs9UKWL+FLrlZyxJfeuGVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWFK/NLP-Semantic-Similarity/blob/main/ClinicalTrials/Data%20Engineering/03.%20InclusionCriteria%20N-Gram%20Frequencies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRDeRGYp_kQD",
        "outputId": "4d27ce7a-1cf8-4fa8-8112-c63eb407ff2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "# pd.set_option('display.max_columns', None)  \n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "import requests\n",
        "from itertools import compress\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### Study #######\n",
        "# lung cancer \n",
        "# NStudiesFound: 10152\n",
        "\n",
        "####### Study Fields #######\n",
        "# NCTId, OrgFullName, OfficialTitle, OverallStatus, Phase, Keyword, DetailedDescription, \n",
        "# Condition, EligibilityCriteria, HealthyVolunteers, Gender, MinimumAge, StudyPopulation, \n",
        "# LocationFacility, LocationCity, LocationCountry\n",
        "\n",
        "####### New Fields to add #######\n",
        "# LocationStatus, Phase\n",
        "\n",
        "####### Deleted Fields #######\n",
        "# LocationState, LocationZip\n",
        "\n",
        "####### Range Min_MAX ######\n",
        "# 1 to 10152\n",
        "\n",
        "####### Format #######\n",
        "# CSV\n",
        "\n",
        "step    = 1000\n",
        "min_rnk = 1\n",
        "max_rnk = step\n",
        "\n",
        "for req in range(11): \n",
        "    \n",
        "    print(\"Downloading Lung Cancer clinical trials with ranks from \", min_rnk, \" to \", max_rnk)\n",
        "    url = 'https://clinicaltrials.gov/api/query/study_fields?expr=lung+cancer&fields=NCTId%2C+OrgFullName%2C+OfficialTitle%2C+OverallStatus%2C+Phase%2C+Keyword%2C+DetailedDescription%2C+%0D%0ACondition%2C+EligibilityCriteria%2C+HealthyVolunteers%2C+Gender%2C+MinimumAge%2C+StudyPopulation%2C+%0D%0ALocationFacility%2C+LocationStatus%2C+LocationCity%2C+LocationCountry&min_rnk='+str(min_rnk)+'&max_rnk='+str(max_rnk)+'&fmt=csv'\n",
        "    session = requests.Session()\n",
        "    retry   = Retry(connect=3, backoff_factor=0.5)\n",
        "    adapter = HTTPAdapter(max_retries=retry)\n",
        "    session.mount('http://' , adapter)\n",
        "    session.mount('https://', adapter)\n",
        "\n",
        "    clinicaltrials = session.get(url)\n",
        "    print('Download Request Status: ', clinicaltrials.status_code)\n",
        "    \n",
        "    csv_file = open('/content/'+str(req)+'-batch.csv', 'wb')\n",
        "    csv_file.write(clinicaltrials.content)\n",
        "    csv_file.close()\n",
        "    \n",
        "    min_rnk = max_rnk + 1\n",
        "    max_rnk += step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9SO00INC7Nv",
        "outputId": "5e93d971-7a71-4a08-d982-1aaa73e2650c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Lung Cancer clinical trials with ranks from  1  to  1000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  1001  to  2000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  2001  to  3000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  3001  to  4000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  4001  to  5000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  5001  to  6000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  6001  to  7000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  7001  to  8000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  8001  to  9000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  9001  to  10000\n",
            "Download Request Status:  200\n",
            "Downloading Lung Cancer clinical trials with ranks from  10001  to  11000\n",
            "Download Request Status:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/0-batch.csv', skiprows=10)\n",
        "for req in range(1, 11): \n",
        "    tmp = pd.read_csv('/content/' +str(req)+ '-batch.csv', skiprows=10)\n",
        "    print('Batch ', req, ': ', tmp.shape)\n",
        "    df = df.append(tmp, ignore_index=True)\n",
        "\n",
        "df.to_csv(r'/content/batchs.csv')\n",
        "print('All Batchs: ',df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q64kIPos-0ub",
        "outputId": "a36d1dea-fb9b-46c6-b5c3-0146b3710b68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch  1 :  (1000, 18)\n",
            "Batch  2 :  (1000, 18)\n",
            "Batch  3 :  (1000, 18)\n",
            "Batch  4 :  (1000, 18)\n",
            "Batch  5 :  (1000, 18)\n",
            "Batch  6 :  (1000, 18)\n",
            "Batch  7 :  (1000, 18)\n",
            "Batch  8 :  (1000, 18)\n",
            "Batch  9 :  (1000, 18)\n",
            "Batch  10 :  (277, 18)\n",
            "All Batchs:  (10277, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the EligibilityCriteria to string then lowercase\n",
        "EligibilityCriteria = df['EligibilityCriteria'].astype(str).str.lower().tolist()\n",
        "EligibilityCriteria[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0KqEf99C8af",
        "outputId": "8cc85556-851a-4eb1-bddc-c60e28cce43d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['inclusion criteria:||age ≥ 18 years at the time of screening.|eastern cooperative oncology group performance status of ≤ 2.|written informed consent obtained from the patient.|histologically and cytologically documented stage 3b-4 lung cancer (according to version 8 of the international association for the study of lung cancer staging system).|patients with stage 1 to 3, who undergo radical therapy with disease free survival (dfs) >12 months.|willingness and ability to comply with scheduled visits and other study procedures.||exclusion criteria:||history of another primary malignancy except for malignancy treated with curative intent with known active disease ≥ 5 years before date of the informed consent.|without signed informed consent.|unwillingness or inability to comply with scheduled visits or other study procedures.|previously diagnosed with vte before signing informed consent.',\n",
              " 'inclusion criteria:||20 or more pack year smoking history|clinical need for diagnostic bronchoscopy or consent to study driven bronchoscopy||exclusion criteria:||lung cancer within 3 months after the date of enrollment',\n",
              " 'inclusion criteria:||aged 40-74 years;|resident in the hexi district of tianjin city for at least 3 years;|having no self-reported history of any malignant tumor.||exclusion criteria:||pregnant woman will be excluded.',\n",
              " 'inclusion criteria:||men or women diagnosed with lung cancer all types and stages confirmed over 12 months of recruitment period by a pathologist||aged at least18 years at diagnosis|patients who provide their informed consent form||exclusion criteria:||patients who did not provide the informed consent form|patients with a mental or psychological disorder according to their treating clinicians',\n",
              " 'inclusion criteria||diagnosis of suspected lung cancer or lung cancer||exclusion criteria||inability to undergo therapy',\n",
              " 'inclusion criteria:||cancer samclinically diagnosed as non-small cell lung samples (mainly lung adenocarcinoma and some lung squamous cell carcinoma, adenosquamous carcinoma, large cell carcinoma, etc.), and a small number of other cancer types are enrolled as interference samples.|collect some samples of relevant medical information before and after the use of targeted drugs. this part of the samples should have relevant previous molecular diagnosis results.|able to provide samples in time according to the requirements of the plan: samples for dna/rna extraction: 10 pieces of 10 µm thickness for each sample or 10 pieces of paraffin rolls. samples for fish experiment: 5 slices of 3-4µm thickness.|the pathological examination conforms to the types of tissue samples listed in the above table. the he staining results show that the tumor content is not less than 50%, and the paraffin slice damage should be avoided.|the sample should have corresponding basic clinical information, including: patient visiting number/medical record number/specimen number, age, gender, pathological diagnosis result, molecular diagnosis result (if any).||exclusion criteria:||those who do not meet any of the above conditions are excluded. reason: the included non-small cell lung adenocarcinoma samples and normal samples should have statistical significance, and the conclusions obtained should be scientific and valid. the selection of subjects for this study, while excluding research-related influencing factors, has no adverse effect on the health of the subjects.',\n",
              " 'inclusion criteria:||receives care at university of utah primary care clinics;|does not already have lung cancer;|meets uspstf criteria for ldct screening (currently, age >= 55 years and <= 80 years old at the time of the visit; 30+ pack-year smoking history and current smoker or quit in the past 15 years) or may meet the criteria if a complete smoking history were taken.||exclusion criteria:||none',\n",
              " \"inclusion criteria:||all individuals with a histologically confirmed diagnosis of lung cancer or a family of lung cancer are eligible to enroll their family in the study. five major histologic types of lung cancer, i.e., adenocardinoma, squamous cell, small cell, large cell, and unspecified nonsmall cell carcinoma will be included. in addition to lung cancer patients, lsu will also contact patients newly diagnosed with bronchus or tracheal cancer in target hospital areas to request their enrollment in their study. in addition, several sites including lsu, mayo clinic and karmanos cancer institute also collect dna samples from unaffected, geographically and ethnically matched controls.||for the purposes of this study, an eligible family must meet the minimum criteria for familial lung cancer: at least 2 first-degree relatives in the family have had lung cancer. priority will be given to more highly loaded pedigrees and to families in which the affected persons had onset of the disease at an early age (less than 50 years). lung cancer cases may be living or deceased. relatives with lung cancer are defined as first- o second-degree relatives or cousins of index cases will be eligible to participate in the study because their familial relationships might provide useful linkage information.||adult participants must be physically able to tolerate removal of 25 to 40 ml of blood, or buccal brush sampling of their cheek. children above 5 years old must be able to physically tolerate an amount of blood drawn that is equal to 4ml/kg of their weight. adults must be willing to complete a self-administered environmental exposure questionnaire, and all participants must be able to consent to the study procedures (or have appropriate assent/parental consent). biological specimens, including blood samples, archived tumor blocks and other medical records will be obtained from patients treated at the various hospitals and collection sites and from individuals with strong family history of lung cancer (either affected or unaffected) who have either been self-referred or physician referred to the study.||exclusion criteria:||excluded from the study are families or individuals within the family who do not meet the minimum criteria described above. individuals who do not sign the consent form will be excluded, and families for whom all necessary members do not sign the consent form may be excluded. mayo also excludes patients who (1) do not speak english, (2) are non-us citizens or residents and (3) are diagnosed with an uncommon tumor type that is not among the above specified types (e.g.) mixed cell or unspecified non-small cell lung cancer, carcinoids, sarcomas and lymphomas of the lung and bronchus). this is done at mayo because the family study is piggy-backed onto a case-control study. no fetuses, prisoners or institutionalized individuals will be enrolled. while this study does not target pregnant women, because contact with many of the families will be by mail we will not be able to exclude pregnant women. additionally, the participant's own physician or health care clinic will draw blood samples from long-distance participants and therefore can determine if there is any risk to the woman or her fetus. umhs also excludes children as research participants in their site.\",\n",
              " 'inclusion criteria:||subjects must meet all of the following criteria||be enrolled in copdgene® phase 1 with or without enrollment in phase 2 with newly diagnosed, (within the time of enrollment), non-small cell lung cancer (nsclc) or small-cell lung cancer (sclc).|documented gold stage 1-4 copd or a history of smoking with no copd|signed hipaa research authorization and a release of protected health information form to collect and review medical records regarding lung cancer diagnosis, treatment, and outcome',\n",
              " 'inclusion criteria:||suspicious finding for lung cancer on ct-scan||exclusion criteria:||history significant for former malignant diseases']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-Grams Frequencies"
      ],
      "metadata": {
        "id": "2Yntf8YdJtoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'this is a foo bar sentences and this is my objective : to ngramize it'\n",
        "ngram = 2 # 15 is the longest sequence, 16 gives an empty list, 17 raises an iteration error\n",
        "print(word_tokenize(text))\n",
        "#nltk.FreqDist(text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSOnAc0gMEJn",
        "outputId": "de32dc36-360a-42a3-83cd-54689ad51c2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'is', 'a', 'foo', 'bar', 'sentences', 'and', 'this', 'is', 'my', 'objective', ':', 'to', 'ngramize', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrams_split(text, ngram):\n",
        "    n_grams = ngrams(word_tokenize(text), ngram)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        "\n",
        "ngrams_split(text, ngram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAZ2f0MeKGdo",
        "outputId": "4b1a3e3a-96a0-486b-f57d-8c7c78edf3c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is',\n",
              " 'is a',\n",
              " 'a foo',\n",
              " 'foo bar',\n",
              " 'bar sentences',\n",
              " 'sentences and',\n",
              " 'and this',\n",
              " 'this is',\n",
              " 'is my',\n",
              " 'my objective',\n",
              " 'objective :',\n",
              " ': to',\n",
              " 'to ngramize',\n",
              " 'ngramize it']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrams_frequency(text, ngram):\n",
        "  bigram_fd = nltk.FreqDist(ngrams_split(text, ngram))\n",
        "  return bigram_fd.most_common()\n",
        "\n",
        "ngrams_frequency(text, ngram)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncbu7cvjL7-v",
        "outputId": "10ea1f3f-146e-4d0f-bcd4-9dac0bb10f95"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this is', 2),\n",
              " ('is a', 1),\n",
              " ('a foo', 1),\n",
              " ('foo bar', 1),\n",
              " ('bar sentences', 1),\n",
              " ('sentences and', 1),\n",
              " ('and this', 1),\n",
              " ('is my', 1),\n",
              " ('my objective', 1),\n",
              " ('objective :', 1),\n",
              " (': to', 1),\n",
              " ('to ngramize', 1),\n",
              " ('ngramize it', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### InclusionCriteria Seperation"
      ],
      "metadata": {
        "id": "q40sXOkdS_Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the EligibilityCriteria to string then lowercase\n",
        "EligibilityCriteria = df['EligibilityCriteria'].astype(str).str.lower().tolist()\n",
        "EligibilityCriteria[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc2Nb7i-TLCH",
        "outputId": "28594f0d-20f8-4b07-c576-16aa1582e318"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['inclusion criteria:||age ≥ 18 years at the time of screening.|eastern cooperative oncology group performance status of ≤ 2.|written informed consent obtained from the patient.|histologically and cytologically documented stage 3b-4 lung cancer (according to version 8 of the international association for the study of lung cancer staging system).|patients with stage 1 to 3, who undergo radical therapy with disease free survival (dfs) >12 months.|willingness and ability to comply with scheduled visits and other study procedures.||exclusion criteria:||history of another primary malignancy except for malignancy treated with curative intent with known active disease ≥ 5 years before date of the informed consent.|without signed informed consent.|unwillingness or inability to comply with scheduled visits or other study procedures.|previously diagnosed with vte before signing informed consent.',\n",
              " 'inclusion criteria:||20 or more pack year smoking history|clinical need for diagnostic bronchoscopy or consent to study driven bronchoscopy||exclusion criteria:||lung cancer within 3 months after the date of enrollment',\n",
              " 'inclusion criteria:||aged 40-74 years;|resident in the hexi district of tianjin city for at least 3 years;|having no self-reported history of any malignant tumor.||exclusion criteria:||pregnant woman will be excluded.',\n",
              " 'inclusion criteria:||men or women diagnosed with lung cancer all types and stages confirmed over 12 months of recruitment period by a pathologist||aged at least18 years at diagnosis|patients who provide their informed consent form||exclusion criteria:||patients who did not provide the informed consent form|patients with a mental or psychological disorder according to their treating clinicians',\n",
              " 'inclusion criteria||diagnosis of suspected lung cancer or lung cancer||exclusion criteria||inability to undergo therapy']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate the InclusionCriteria from the ExclusionCriteria\n",
        "InclusionCriteria = [txt[21:txt.find('exclusion criteria')-2] for txt in EligibilityCriteria]\n",
        "InclusionCriteria[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmoqcrj8Tdaz",
        "outputId": "f06a3eb1-faab-48c4-86fe-4bbdac7927ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age ≥ 18 years at the time of screening.|eastern cooperative oncology group performance status of ≤ 2.|written informed consent obtained from the patient.|histologically and cytologically documented stage 3b-4 lung cancer (according to version 8 of the international association for the study of lung cancer staging system).|patients with stage 1 to 3, who undergo radical therapy with disease free survival (dfs) >12 months.|willingness and ability to comply with scheduled visits and other study procedures.',\n",
              " '20 or more pack year smoking history|clinical need for diagnostic bronchoscopy or consent to study driven bronchoscopy',\n",
              " 'aged 40-74 years;|resident in the hexi district of tianjin city for at least 3 years;|having no self-reported history of any malignant tumor.',\n",
              " 'men or women diagnosed with lung cancer all types and stages confirmed over 12 months of recruitment period by a pathologist||aged at least18 years at diagnosis|patients who provide their informed consent form',\n",
              " 'iagnosis of suspected lung cancer or lung cancer']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split each Trial InclusionCriteria into list of lists of the InclusionCriteria\n",
        "InclusionCriteriaList = list(map(lambda txt : txt.split(\"|\"), InclusionCriteria))\n",
        "InclusionCriteriaList = [list(filter(lambda txt: txt!= '', ltexts)) for ltexts in InclusionCriteriaList] # Delete the empty string generated by successive || (sometimes they seperate with | or ||)\n",
        "print(len(InclusionCriteriaList))\n",
        "InclusionCriteriaList[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwPw9pxqUMVb",
        "outputId": "b0d17ea0-9412-40bc-cd0f-e922f1bfbe39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['age ≥ 18 years at the time of screening.',\n",
              "  'eastern cooperative oncology group performance status of ≤ 2.',\n",
              "  'written informed consent obtained from the patient.',\n",
              "  'histologically and cytologically documented stage 3b-4 lung cancer (according to version 8 of the international association for the study of lung cancer staging system).',\n",
              "  'patients with stage 1 to 3, who undergo radical therapy with disease free survival (dfs) >12 months.',\n",
              "  'willingness and ability to comply with scheduled visits and other study procedures.'],\n",
              " ['20 or more pack year smoking history',\n",
              "  'clinical need for diagnostic bronchoscopy or consent to study driven bronchoscopy']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert the InclusionCriteria from a list of lists to a list\n",
        "InclusionCriteriaList_Flat  = [item for sublist in InclusionCriteriaList for item in sublist]\n",
        "print(len(InclusionCriteriaList_Flat))\n",
        "InclusionCriteriaList_Flat[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6BSQj0VUakt",
        "outputId": "cdaee61b-6d6b-48e0-d53a-3700b5b856ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age ≥ 18 years at the time of screening.',\n",
              " 'eastern cooperative oncology group performance status of ≤ 2.',\n",
              " 'written informed consent obtained from the patient.',\n",
              " 'histologically and cytologically documented stage 3b-4 lung cancer (according to version 8 of the international association for the study of lung cancer staging system).',\n",
              " 'patients with stage 1 to 3, who undergo radical therapy with disease free survival (dfs) >12 months.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### InclusionCriteria N-Grams Frequencies"
      ],
      "metadata": {
        "id": "_aFcruxZgv5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Join all texts into one text\n",
        "AllInclusionCriteria = \" \".join(InclusionCriteriaList_Flat)\n",
        "print(len(AllInclusionCriteria))\n",
        "print(len(AllInclusionCriteria.split(' ')))\n",
        "\n",
        "ngrams_frequency(AllInclusionCriteria, 1)[:5]\n",
        "\n",
        "# => we need to remove the punctuation, stopwords, tag the words then lemmatize them."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzBDr63ofcYS",
        "outputId": "849ba04f-db92-43c8-dd34-127092cc0e2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12455372\n",
            "1858694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 59678), ('of', 59235), ('or', 56170), (')', 49932), ('(', 49015)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    return \"\".join([i for i in text if i not in string.punctuation])"
      ],
      "metadata": {
        "id": "NqDAHGuLhqIQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in word_tokenize(text) if not word in stopwords.words('english')])"
      ],
      "metadata": {
        "id": "yMqtZjgQiDK7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'''\n",
        "Part-of-speech tagging, words, or tokens are assigned part of speech tags, which are typically morphosyntactic subtypes of fundamental syntactic \n",
        "categories in the language such as a noun, or verb. By lemmatizing lexemes, inflected forms of a word are grouped together under a common root. \n",
        "\n",
        "The tagging and lemmatization of parts of speech are essential to linguistic pre-processing. This website uses morphosyntactic descriptors and \n",
        "part-of-speech tagging as acronyms. In the context of the NLTK Lemmatization, the part of speech tags are pre-defined with shortcuts for the \n",
        "NLTK WordNetLemmatizer as below.\n",
        "\n",
        "https://www.holisticseo.digital/python-seo/nltk/lemmatize\n",
        "'''"
      ],
      "metadata": {
        "id": "un4jbb5Xqekl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom tagger, so the tags can be interpreted by the WordNetLemmatizer()\n",
        "# Because NLTK nltk.pos_tag() and WordNetLemmatizer() do not use the same naming covention\n",
        "def nltk_pos_tagger(nltk_tag):\n",
        "  \n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None"
      ],
      "metadata": {
        "id": "wdZ2YX61qiwS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_lemmatize_sentence(sentence):\n",
        "\n",
        "    # Tag the Tokenized text\n",
        "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
        "\n",
        "    # Aply the custom tagger, so the tags can be interpreted by the WordNetLemmatizer()\n",
        "    wordnet_tagged = map(lambda x: (x[0], nltk_pos_tagger(x[1])), nltk_tagged)\n",
        "    \n",
        "    lemmatized_sentence = []\n",
        "    for word, tag in wordnet_tagged:\n",
        "        if tag is None:\n",
        "            lemmatized_sentence.append(word)\n",
        "        else:        \n",
        "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
        "    return \" \".join(lemmatized_sentence)\n",
        "\n",
        "sentence = \"I am voting for better that politician. in this NLTK, Lemmatization example sentences\"\n",
        "print(sentence) \n",
        "print(tag_lemmatize_sentence(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bADjwkuXnFn7",
        "outputId": "963b0010-70ef-46e3-95ba-74bea03b5129"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am voting for better that politician. in this NLTK, Lemmatization example sentences\n",
            "I be vote for good that politician . in this NLTK , Lemmatization example sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence)\n",
        "print(remove_punctuation(sentence))\n",
        "print(remove_stopwords(remove_punctuation(sentence)))\n",
        "print(lemmatizer.lemmatize(remove_stopwords(remove_punctuation(sentence))))\n",
        "print(tag_lemmatize_sentence(remove_stopwords(remove_punctuation(sentence))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjWkr8Zyuol2",
        "outputId": "9863cb0d-d7a5-4f2e-b71f-e5c1b255670e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am voting for better that politician. in this NLTK, Lemmatization example sentences\n",
            "I am voting for better that politician in this NLTK Lemmatization example sentences\n",
            "I voting better politician NLTK Lemmatization example sentences\n",
            "I voting better politician NLTK Lemmatization example sentences\n",
            "I vote well politician NLTK Lemmatization example sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Join all texts into one text\n",
        "AllInclusionCriteria = \" \".join(InclusionCriteriaList_Flat)\n",
        "print(len(AllInclusionCriteria))\n",
        "print(len(AllInclusionCriteria.split(' ')))\n",
        "\n",
        "ngrams_frequency(AllInclusionCriteria, 1)[:5]\n",
        "# => we need to remove the punctuation, stopwords, tag the words then lemmatize them."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e3prniG3Ixg",
        "outputId": "e15abb61-ab6d-4694-e9ed-fbbad1e81d4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12455372\n",
            "1858694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 59678), ('of', 59235), ('or', 56170), (')', 49932), ('(', 49015)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ProcessedAllInclusionCriteria = tag_lemmatize_sentence(remove_stopwords(remove_punctuation(AllInclusionCriteria)))\n",
        "print(len(ProcessedAllInclusionCriteria))\n",
        "print(len(ProcessedAllInclusionCriteria.split(' ')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN7Q3kJr2yIl",
        "outputId": "59cc0d79-2715-4fb8-cd56-c5b8cd287c95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9723252\n",
            "1294528\n",
            "CPU times: user 5min 32s, sys: 28.3 s, total: 6min\n",
            "Wall time: 6min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for ngram in range(1,85):\n",
        "  #data = ngrams_frequency(ProcessedAllInclusionCriteria, ngram)\n",
        "  #data_df = pd.DataFrame(data, columns=['Phrase', 'Frequency']).head(100)\n",
        "  #print('For N-Grams=', ngram, 'The most frequent phrases are: \\n', data[:10],'\\n\\n')\n",
        "  pd.DataFrame(ngrams_frequency(ProcessedAllInclusionCriteria, ngram), columns=['Phrase', 'Frequency']).head(100).to_excel(str(str(ngram) + ' Words per sentence.xlsx'), index=False)\n",
        "  files.download(str(str(ngram) + ' Words per sentence.xlsx'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ENe-CCjY39Lt",
        "outputId": "a1752e39-617e-4d07-8571-566ed1494f25"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_53fec9c6-f06c-4ebc-b2b0-fa543d1053f8\", \"1 Words per sentence.xlsx\", 6624)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ce8c7198-739a-42dc-a46f-b28caaf3d553\", \"2 Words per sentence.xlsx\", 6868)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0095375c-753c-4574-85f6-3ee6173a4600\", \"3 Words per sentence.xlsx\", 7002)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_edb5f189-c1f8-4f96-9965-580a8aa82500\", \"4 Words per sentence.xlsx\", 7101)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 35.2 s, sys: 158 ms, total: 35.4 s\n",
            "Wall time: 36 s\n"
          ]
        }
      ]
    }
  ]
}