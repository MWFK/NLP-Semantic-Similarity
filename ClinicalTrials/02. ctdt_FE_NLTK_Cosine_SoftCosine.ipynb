{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02. ct_dt-FE-NLTK-Cosine_SoftCosine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9DvIlxG4Xkg29GMuuLd+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWFK/NLP-Semantic-Similarity/blob/main/ClinicalTrials/02.%20ctdt_FE_NLTK_Cosine_SoftCosine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libs\n"
      ],
      "metadata": {
        "id": "aAZ7FaR0TYuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python libs to manipulate dataframes and arrays\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# To get the word vectors, you need a word embedding model. Let’s download the FastText model using gensim’s downloader api.\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "\n",
        "# upgrade gensim if you can't import softcossim\n",
        "from gensim.matutils import softcossim \n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "1AvcPKRQTdOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27427ce7-822a-4782-a206-ac24576b60ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "_o9OBX3vTltL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the documents\n",
        "doc_trump    = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin\"\n",
        "doc_election = \"President Trump says Putin had no political interference in the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election\"\n",
        "doc_putin    = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career\"\n",
        "documents    = [doc_trump, doc_election, doc_putin]"
      ],
      "metadata": {
        "id": "V9GeOdAMS1Hw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling using Cosine as a metric\n",
        "\n",
        "To compute the cosine similarity, you need the word count of the words in each document. The CountVectorizer or the TfidfVectorizer from scikit learn lets us compute this. The output of this comes as a sparse_matrix. On this, am optionally converting it to a pandas dataframe to see the word frequencies in a tabular format.\n",
        "\n",
        "Even better, I could have used the TfidfVectorizer() instead of CountVectorizer(), because it would have downweighted words that occur frequently across docuemnts. Then, use cosine_similarity() to get the final output. It can take the document term matri as a pandas dataframe as well as a sparse matrix as inputs."
      ],
      "metadata": {
        "id": "eyffv8_zT-__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ud-bFuNNSsqp",
        "outputId": "2893305d-657d-4c76-844e-4c8910227f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2cb9bb32-0712-436a-86d7-18244408ba24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>career</th>\n",
              "      <th>claimed</th>\n",
              "      <th>earlier</th>\n",
              "      <th>election</th>\n",
              "      <th>elections</th>\n",
              "      <th>friend</th>\n",
              "      <th>friends</th>\n",
              "      <th>interference</th>\n",
              "      <th>lost</th>\n",
              "      <th>minister</th>\n",
              "      <th>mr</th>\n",
              "      <th>outcome</th>\n",
              "      <th>parties</th>\n",
              "      <th>political</th>\n",
              "      <th>post</th>\n",
              "      <th>president</th>\n",
              "      <th>prime</th>\n",
              "      <th>putin</th>\n",
              "      <th>republican</th>\n",
              "      <th>russia</th>\n",
              "      <th>says</th>\n",
              "      <th>served</th>\n",
              "      <th>support</th>\n",
              "      <th>trump</th>\n",
              "      <th>vladimir</th>\n",
              "      <th>winning</th>\n",
              "      <th>witchhunt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc_trump</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc_election</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc_putin</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cb9bb32-0712-436a-86d7-18244408ba24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cb9bb32-0712-436a-86d7-18244408ba24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cb9bb32-0712-436a-86d7-18244408ba24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              career  claimed  earlier  ...  vladimir  winning  witchhunt\n",
              "doc_trump          0        0        0  ...         0        1          0\n",
              "doc_election       0        1        0  ...         0        0          1\n",
              "doc_putin          1        0        1  ...         1        0          0\n",
              "\n",
              "[3 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Create the Document Term Matrix\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "sparse_matrix    = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
        "doc_term_matrix = sparse_matrix.todense()\n",
        "df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names(), index=['doc_trump', 'doc_election', 'doc_putin'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(df, df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghwxa-5XS_VZ",
        "outputId": "dd5278db-15b4-4c68-f771-c0b3f4e104c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.51639778 0.36893239]\n",
            " [0.51639778 1.         0.45360921]\n",
            " [0.36893239 0.45360921 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling using SoftCosine as a metric\n",
        "\n",
        "Suppose if you have another set of documents on a completely different topic, say ‘food’, you want a similarity metric that gives higher scores for documents belonging to the same topic and lower scores when comparing docs from different topics. In such case, we need to consider the semantic meaning should be considered. That is, words similar in meaning should be treated as similar. For Example, ‘President’ vs ‘Prime minister’, ‘Food’ vs ‘Dish’, ‘Hi’ vs ‘Hello’ should be considered similar. For this, converting the words into respective word vectors, and then, computing the similarities can address this problem."
      ],
      "metadata": {
        "id": "_Fosa9bSWemn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the documents\n",
        "doc_soup = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid. \"\n",
        "doc_noodles = \"Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"\n",
        "doc_dosa = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"\n",
        "documents = [doc_trump, doc_election, doc_putin, doc_soup, doc_noodles, doc_dosa]"
      ],
      "metadata": {
        "id": "G5P54pykTLGL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Download the FastText model\n",
        "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PGEFnrVXEwI",
        "outputId": "6c6a4667-c020-4b9b-ece5-66c250b703c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "CPU times: user 9min 36s, sys: 27 s, total: 10min 3s\n",
            "Wall time: 11min 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a dictionary and a corpus.\n",
        "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
        "\n",
        "# Prepare the similarity matrix\n",
        "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
        "\n",
        "# Convert the sentences into bag-of-words vectors.\n",
        "sent_1 = dictionary.doc2bow(simple_preprocess(doc_trump))\n",
        "sent_2 = dictionary.doc2bow(simple_preprocess(doc_election))\n",
        "sent_3 = dictionary.doc2bow(simple_preprocess(doc_putin))\n",
        "sent_4 = dictionary.doc2bow(simple_preprocess(doc_soup))\n",
        "sent_5 = dictionary.doc2bow(simple_preprocess(doc_noodles))\n",
        "sent_6 = dictionary.doc2bow(simple_preprocess(doc_dosa))\n",
        "\n",
        "sentences = [sent_1, sent_2, sent_3, sent_4, sent_5, sent_6]"
      ],
      "metadata": {
        "id": "2wdqloflXRmZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute soft cosine similarity for two sentences\n",
        "print(softcossim(sent_1, sent_2, similarity_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8eYuO4WaEkT",
        "outputId": "52de17b7-990b-4e78-edf6-959b00009d4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5885144994929364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute soft cosine similarity for all sentences\n",
        "def create_soft_cossim_matrix(sentences):\n",
        "    len_array = np.arange(len(sentences))\n",
        "    xx, yy = np.meshgrid(len_array, len_array)\n",
        "    cossim_mat = pd.DataFrame([[round(softcossim(sentences[i],sentences[j], similarity_matrix) ,2) for i, j in zip(x,y)] for y, x in zip(xx, yy)])\n",
        "    return cossim_mat\n",
        "\n",
        "create_soft_cossim_matrix(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "r69WWzMNaSHe",
        "outputId": "137401ca-62c7-4454-9d5d-1e02f471bb20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a165e80b-9c09-4d41-ae50-2d50019a6a67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.59</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a165e80b-9c09-4d41-ae50-2d50019a6a67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a165e80b-9c09-4d41-ae50-2d50019a6a67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a165e80b-9c09-4d41-ae50-2d50019a6a67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0     1     2     3     4     5\n",
              "0  1.00  0.59  0.56  0.28  0.34  0.40\n",
              "1  0.59  1.00  0.56  0.23  0.33  0.45\n",
              "2  0.56  0.56  1.00  0.19  0.25  0.36\n",
              "3  0.28  0.23  0.19  1.00  0.50  0.38\n",
              "4  0.34  0.33  0.25  0.50  1.00  0.56\n",
              "5  0.40  0.45  0.36  0.38  0.56  1.00"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with real data"
      ],
      "metadata": {
        "id": "7KkVUiCgN0fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python libs to manipulate dataframes and arrays\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# To get the word vectors, you need a word embedding model. Let’s download the FastText model using gensim’s downloader api.\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "\n",
        "# upgrade gensim if you can't import softcossim\n",
        "from gensim.matutils import softcossim \n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSKOvP-AEo-p",
        "outputId": "a2fbb014-9557-425a-f40c-066009449f27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "\n",
        "  # Download Clinical Trials data\n",
        "  print('Downloading Clinical Trials Data')\n",
        "  ct_dt = pd.read_csv(r'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_0.csv', sep=',', engine='python', encoding=\"utf-8\")\n",
        "  for btch in range(1, 4):\n",
        "      url = 'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_' +str(btch)+ '.csv'\n",
        "      tmp = pd.read_csv(url, sep=',', engine='python', encoding=\"ISO-8859-1\")\n",
        "      ct_dt = ct_dt.append(tmp, ignore_index=True)\n",
        "  ct_dt['AllLocation'] = ct_dt['LocationCity'].str.lower().map(str) + ' | ' + ct_dt['LocationState'].str.lower().map(str) + ' | ' + ct_dt['LocationCountry'].str.lower().map(str)\n",
        "  print('Clinical Trials Data: ',ct_dt.shape, '\\n')\n",
        "\n",
        "  # Download User input data\n",
        "  print('Downloading Test data')\n",
        "  test = pd.read_csv('https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/TestData.csv', sep=';', engine='python', encoding = \"utf-8\", skiprows=[0], names=['PatientID','ConditionOrDisease','Age','Gender','LocationCountry','TravelDistance','InclusionCriteria'])\n",
        "  print('Test Data: ', test.shape)\n",
        "\n",
        "  return ct_dt, test\n",
        "\n",
        "ct_dt, test = get_data()"
      ],
      "metadata": {
        "id": "agm04fIpm9Pv",
        "outputId": "15a70555-8327-4e8c-83b1-1cfae77cdd7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Clinical Trials Data\n",
            "Clinical Trials Data:  (10152, 21) \n",
            "\n",
            "Downloading Test data\n",
            "Test Data:  (7, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_processing(ct_dt):\n",
        "\n",
        "  print('Data dimensions before Filtering : ', ct_dt.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Age ###\n",
        "  print('Filtering by Age...')\n",
        "  tmp = ct_dt[ct_dt.iloc[:,13] <= test.iloc[:1,2][0]]               # compare numerics\n",
        "  tmp = tmp[tmp.iloc[:,13].str.find(test.iloc[:1,2][0][-5:]) != -1] # Detect the Year/Month\n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Gender ###\n",
        "  print('Filtering by Gender...')\n",
        "  tmp = tmp[(tmp.iloc[:,12] == test.iloc[:1,3][0]) | (tmp.iloc[:,12] == 'All')] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Travel Distance ###\n",
        "  print('Filtering by Travel Distance...')\n",
        "  tmp = tmp[tmp.iloc[:,20].str.find(test.iloc[:1,5][0].lower()) != -1] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  return tmp\n",
        "\n",
        "tmp = data_processing(ct_dt)\n"
      ],
      "metadata": {
        "id": "1dkSn6WkotTV",
        "outputId": "b4182aee-c542-4899-fd6a-277be3042afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dimensions before Filtering :  (10152, 21) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9517, 21) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9403, 21) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (645, 21) \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e923d1ce-82a1-495e-b3b3-fd9b12fef87c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>NCTId</th>\n",
              "      <th>OrgFullName</th>\n",
              "      <th>OfficialTitle</th>\n",
              "      <th>OverallStatus</th>\n",
              "      <th>Keyword</th>\n",
              "      <th>DetailedDescription</th>\n",
              "      <th>Condition</th>\n",
              "      <th>EligibilityCriteria</th>\n",
              "      <th>InclusionCriteria</th>\n",
              "      <th>ExclusionCriteria</th>\n",
              "      <th>HealthyVolunteers</th>\n",
              "      <th>Gender</th>\n",
              "      <th>MinimumAge</th>\n",
              "      <th>StudyPopulation</th>\n",
              "      <th>LocationFacility</th>\n",
              "      <th>LocationCity</th>\n",
              "      <th>LocationState</th>\n",
              "      <th>LocationZip</th>\n",
              "      <th>LocationCountry</th>\n",
              "      <th>AllLocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>NCT02603627</td>\n",
              "      <td>Guy's and St Thomas' NHS Foundation Trust</td>\n",
              "      <td>Cross-sectional Study to Compare the Prevalenc...</td>\n",
              "      <td>Unknown status</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chronic obstructive pulmonary disease (COPD) i...</td>\n",
              "      <td>COPD|Lung Cancer|Smoking</td>\n",
              "      <td>Inclusion Criteria:||Informed consent|Aged ove...</td>\n",
              "      <td>Informed consent|Aged over 18|Lung cancer grou...</td>\n",
              "      <td>Patient refusal|Age under 18|Control group: pr...</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>Patients will be recruited from the multidisci...</td>\n",
              "      <td>Guy's and St Thomas' NHS Foundation Trust</td>\n",
              "      <td>London</td>\n",
              "      <td>England</td>\n",
              "      <td>SE1 9RT</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>london | england | united kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>80</td>\n",
              "      <td>NCT04629079</td>\n",
              "      <td>King's College London</td>\n",
              "      <td>Lung Cancer Detection Using Blood Exosomes and...</td>\n",
              "      <td>Recruiting</td>\n",
              "      <td>Early detection</td>\n",
              "      <td>Lung cancer is the leading cause of cancer dea...</td>\n",
              "      <td>Lung Cancer</td>\n",
              "      <td>Inclusion Criteria:||Over 18 years of age|Susp...</td>\n",
              "      <td>Over 18 years of age|Suspected clinical diagno...</td>\n",
              "      <td>-Synchronous other cancer types.</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>The study will include patients who have been ...</td>\n",
              "      <td>Borthwick Research Unit, Lister Hospital</td>\n",
              "      <td>Stevenage</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SG1 4AB</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>stevenage | nan | united kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>89</td>\n",
              "      <td>NCT02612532</td>\n",
              "      <td>Owlstone Ltd</td>\n",
              "      <td>Lung Cancer Indicator Detection</td>\n",
              "      <td>Active, not recruiting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rationale Approximately 75% of patients with l...</td>\n",
              "      <td>Lung Cancer</td>\n",
              "      <td>Recruitment for these patients will be done fr...</td>\n",
              "      <td>patients will be done from NHS hospitals whom...</td>\n",
              "      <td>e patients will be done from NHS hospitals who...</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UZA University Hospital Antwerp|UZG University...</td>\n",
              "      <td>Antwerp|Gent|Leipzig|Bari|Cambridge|Buckingham...</td>\n",
              "      <td>Cambridgeshire</td>\n",
              "      <td>04103</td>\n",
              "      <td>Belgium|Belgium|Germany|Italy|United Kingdom|U...</td>\n",
              "      <td>antwerp|gent|leipzig|bari|cambridge|buckingham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>101</td>\n",
              "      <td>NCT04178889</td>\n",
              "      <td>Papworth Hospital NHS Foundation Trust</td>\n",
              "      <td>Second Primary Lung Cancer Cohort Study (SPORT)</td>\n",
              "      <td>Recruiting</td>\n",
              "      <td>Lung cancer|Non-small cell lung cancer</td>\n",
              "      <td>This is a multi-centre, observational basic sc...</td>\n",
              "      <td>Lung Cancer</td>\n",
              "      <td>Inclusion Criteria:||previous treatment with c...</td>\n",
              "      <td>previous treatment with curative intent (surge...</td>\n",
              "      <td>Primary lung tumour was a carcinoid tumour|in ...</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>Patients who have been treated with curative i...</td>\n",
              "      <td>Royal Papworth Hospital</td>\n",
              "      <td>Cambridge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>cambridge | nan | united kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>104</td>\n",
              "      <td>NCT04409444</td>\n",
              "      <td>Manchester University NHS Foundation Trust</td>\n",
              "      <td>An Observational Cohort Study Investigating th...</td>\n",
              "      <td>Recruiting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lung Cancer</td>\n",
              "      <td>Main data study:||Inclusion Criteria:||- Any i...</td>\n",
              "      <td>lusion Criteria:||- Any individual attending t...</td>\n",
              "      <td>- Unable to give informed consent to study par...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All</td>\n",
              "      <td>55 Years</td>\n",
              "      <td>Individuals will be attending a lung health ch...</td>\n",
              "      <td>Manchester University NHS Trust</td>\n",
              "      <td>Manchester</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>manchester | nan | united kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10041</th>\n",
              "      <td>10042</td>\n",
              "      <td>NCT04385160</td>\n",
              "      <td>Fondazione per la Ricerca Ospedale Maggiore</td>\n",
              "      <td>Myeloproliferative Neoplasms (MPN) and COVID-19</td>\n",
              "      <td>Recruiting</td>\n",
              "      <td>thrombosis</td>\n",
              "      <td>This is an European multicenter observational ...</td>\n",
              "      <td>Myeloproliferative Neoplasm|COVID</td>\n",
              "      <td>Inclusion Criteria:||Age &gt; 18 years|Confirmed ...</td>\n",
              "      <td>Age &gt; 18 years|Confirmed diagnosed of MPN acco...</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>Patients with Myeloproliferative Neoplasm (Pol...</td>\n",
              "      <td>New York-Presbyterian/Weill Cornell Medical Ce...</td>\n",
              "      <td>New York|Zagreb|Paris|Aachen|Minden|Monza|Ales...</td>\n",
              "      <td>New York|Monza Brianza|Barcellona|Barcellona|B...</td>\n",
              "      <td>10065|20900|15121|24127|40138|25123|50134|2012...</td>\n",
              "      <td>United States|Croatia|France|Germany|Germany|I...</td>\n",
              "      <td>new york|zagreb|paris|aachen|minden|monza|ales...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10044</th>\n",
              "      <td>10045</td>\n",
              "      <td>NCT01334593</td>\n",
              "      <td>Liverpool University Hospitals NHS Foundation ...</td>\n",
              "      <td>The Effect of Neoadjuvant Chemoradiotherapy on...</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Purpose: To evaluate the effects of chemoradio...</td>\n",
              "      <td>Cancer</td>\n",
              "      <td>Inclusion Criteria:||All patients listed to un...</td>\n",
              "      <td>All patients listed to undergo neoadjuvant che...</td>\n",
              "      <td>Unable to consent.|Under 18 years of age.|Sign...</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>Colorectal cancer is the third commonest cause...</td>\n",
              "      <td>Aintree University Hospitals</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Merseyside</td>\n",
              "      <td>L7 8XP</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>liverpool | merseyside | united kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10086</th>\n",
              "      <td>10087</td>\n",
              "      <td>NCT03828578</td>\n",
              "      <td>Cardiff and Vale University Health Board</td>\n",
              "      <td>Comparison of AIRVO High Flow Oxygen Therapy W...</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Major head and neck surgery involving micro-va...</td>\n",
              "      <td>Head and Neck Cancer</td>\n",
              "      <td>Inclusion Criteria:||Undergoing head and neck ...</td>\n",
              "      <td>Undergoing head and neck surgery with microvas...</td>\n",
              "      <td>Under 18 years old|Lack of consent|Consultant ...</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cardiff and Vale University Health Board</td>\n",
              "      <td>Cardiff</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CF144XW</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>cardiff | nan | united kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10098</th>\n",
              "      <td>10099</td>\n",
              "      <td>NCT00324298</td>\n",
              "      <td>National Cancer Institute (NCI)</td>\n",
              "      <td>A Randomized Phase III Toxicity Study of Day 2...</td>\n",
              "      <td>Completed</td>\n",
              "      <td>drug/agent toxicity by tissue/organ|stage III ...</td>\n",
              "      <td>OBJECTIVES:||Primary||Determine if long-infusi...</td>\n",
              "      <td>Drug/Agent Toxicity by Tissue/Organ|Testicular...</td>\n",
              "      <td>DISEASE CHARACTERISTICS:||Diagnosis of metasta...</td>\n",
              "      <td>CS:||Diagnosis of metastatic germ cell cancer ...</td>\n",
              "      <td>ICS:||Diagnosis of metastatic germ cell cancer...</td>\n",
              "      <td>No</td>\n",
              "      <td>Male</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Basildon University Hospital|Addenbrooke's Hos...</td>\n",
              "      <td>Basildon|Cambridge|Colchester|Ipswich|Leeds|Lo...</td>\n",
              "      <td>England|England|England|England|England|Englan...</td>\n",
              "      <td>SS16 5NL|CB2 2QQ|C03 3NB|IP4 5PD|LS9 7TF|EC1A ...</td>\n",
              "      <td>United Kingdom|United Kingdom|United Kingdom|U...</td>\n",
              "      <td>basildon|cambridge|colchester|ipswich|leeds|lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10115</th>\n",
              "      <td>10116</td>\n",
              "      <td>NCT03862911</td>\n",
              "      <td>British Columbia Cancer Agency</td>\n",
              "      <td>Phase III Randomized Controlled Trial and Econ...</td>\n",
              "      <td>Recruiting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TREATMENT PLAN||5.1.1 Standard Arm (Arm 1)||Ra...</td>\n",
              "      <td>Metastatic Tumors</td>\n",
              "      <td>Inclusion Criteria:||Total number of metastase...</td>\n",
              "      <td>Total number of metastases of 1-3|Age 18 or ol...</td>\n",
              "      <td>Previous SABR to the lesion(s)|Lesion in femor...</td>\n",
              "      <td>No</td>\n",
              "      <td>All</td>\n",
              "      <td>18 Years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alfred Hospital|Tom Baker Cancer Centre|BC Can...</td>\n",
              "      <td>Melbourne|Calgary|Kelowna|Prince George|Surrey...</td>\n",
              "      <td>Victoria|Alberta|British Columbia|British Colu...</td>\n",
              "      <td>3004|T2N 4N2|V1Y 5L3|V2M 7E9|B3H 1V8|6|D18 AK68</td>\n",
              "      <td>Australia|Canada|Canada|Canada|Canada|Canada|C...</td>\n",
              "      <td>melbourne|calgary|kelowna|prince george|surrey...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>645 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e923d1ce-82a1-495e-b3b3-fd9b12fef87c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e923d1ce-82a1-495e-b3b3-fd9b12fef87c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e923d1ce-82a1-495e-b3b3-fd9b12fef87c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Rank  ...                                        AllLocation\n",
              "52        53  ...                  london | england | united kingdom\n",
              "79        80  ...                   stevenage | nan | united kingdom\n",
              "88        89  ...  antwerp|gent|leipzig|bari|cambridge|buckingham...\n",
              "100      101  ...                   cambridge | nan | united kingdom\n",
              "103      104  ...                  manchester | nan | united kingdom\n",
              "...      ...  ...                                                ...\n",
              "10041  10042  ...  new york|zagreb|paris|aachen|minden|monza|ales...\n",
              "10044  10045  ...            liverpool | merseyside | united kingdom\n",
              "10086  10087  ...                     cardiff | nan | united kingdom\n",
              "10098  10099  ...  basildon|cambridge|colchester|ipswich|leeds|lo...\n",
              "10115  10116  ...  melbourne|calgary|kelowna|prince george|surrey...\n",
              "\n",
              "[645 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling using Cosine as a metric\n",
        "\n",
        "To compute the cosine similarity, you need the word count of the words in each document. The CountVectorizer or the TfidfVectorizer from scikit learn lets us compute this. The output of this comes as a sparse_matrix. On this, am optionally converting it to a pandas dataframe to see the word frequencies in a tabular format.\n",
        "\n",
        "Even better, I could have used the TfidfVectorizer() instead of CountVectorizer(), because it would have downweighted words that occur frequently across docuemnts. Then, use cosine_similarity() to get the final output. It can take the document term matri as a pandas dataframe as well as a sparse matrix as inputs."
      ],
      "metadata": {
        "id": "azMRmaKV2KDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "ct_dt['InclusionCriteria'] = ct_dt['InclusionCriteria'].fillna(' ')\n",
        "tmp['InclusionCriteria']   = tmp['InclusionCriteria'].fillna(' ')\n",
        "\n",
        "count_vectorizer           = CountVectorizer(stop_words='english')\n",
        "count_vectorizer_ct_dt     = count_vectorizer.fit(ct_dt['InclusionCriteria'])\n",
        "\n",
        "count_vectorizer_tmp       = count_vectorizer_ct_dt.transform(tmp['InclusionCriteria'])\n",
        "\n",
        "count_vectorizer_test0    = count_vectorizer_ct_dt.transform(test.iloc[:1,6].fillna(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjKowLYXlwl7",
        "outputId": "180e0df9-a540-4c81-999f-f78469bfd87e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.76 s, sys: 30.4 ms, total: 2.79 s\n",
            "Wall time: 3.58 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(cosine_similarity(count_vectorizer_test0 , count_vectorizer_tmp)))\n",
        "# print(cosine_similarity(count_vectorizer_test0 , count_vectorizer_tmp).shape)\n",
        "# print(cosine_similarity(count_vectorizer_test0 , count_vectorizer_tmp))\n",
        "# print(cosine_similarity(count_vectorizer_test0 , count_vectorizer_tmp)[0])\n",
        "print(*test.iloc[:1,6])\n",
        "print(*tmp.iloc[2:3,9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6g0nt4N7zaG",
        "outputId": "c5b09cb2-ebd1-4b6b-8807-e57bcc2d7c5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Histologically diagnosed with metastatic non-small cell lung cancer in 2018 | Initially treated with pertuzumab but relapsed | His performance status is ECOG 1 or KPS 90 | His blood and liver function analysis show normal | No other indications like HIV, HCV, HBV | No allergies | Life expectancy over 6 months | No mental disabilities.\n",
            " patients will be done from NHS hospitals whom identify or follow-up on patients suspected of having lung cancer.||Inclusion criteria:||Older than 18 years at time of consent||Referred for investigation due to suspicion of lung cancer||Referral based on suspicious symptoms|Referral based on suspicious finding on imaging, including CTscan with indeterminate nodule requiring follow-up evaluation.|Capable of understanding written and/or spoken language|Able to provide informed consent||Exclusion criteria:||(Anticipated) inability to complete breath sampling procedure due to e.g. hyper- or hypo-ventilation, respiratory failure or claustrophobia when wearing the sampling mask|Participating in a Clinical Trial Investigational Medicinal Product (CTIMP)|Pulmonary function test with metacholine or beta-2-sympatico mimetic in last 2 hours.|Any lung biopsy in the past 48 hours|Currently undergoing anti-cancer treatment for lung cance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp['Similarity'] = pd.Series(cosine_similarity(count_vectorizer_test0, count_vectorizer_tmp)[0]).values\n",
        "\n",
        "ct_dt_tmp = ct_dt\n",
        "ct_dt_tmp['Similarity'] = 0\n",
        "print(ct_dt_tmp.shape)\n",
        "print(tmp.shape)\n",
        "\n",
        "ct_dt_tmp = ct_dt_tmp[~ct_dt_tmp['NCTId'].isin(tmp['NCTId'])]\n",
        "print(ct_dt_tmp.shape)\n",
        "ct_dt_tmp = ct_dt_tmp.append(tmp, ignore_index=True)\n",
        "\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.1].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.2].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.25].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.3].shape)\n",
        "\n",
        "ct_dt_tmp['Similarity'] = ct_dt_tmp['Similarity'].apply(lambda score: score if score>0.25 else 0)\n",
        "ct_dt_tmp = ct_dt_tmp.sort_values(by=['Similarity'], ascending=False)"
      ],
      "metadata": {
        "id": "DS8Oz0SLmJjU",
        "outputId": "3be8b82f-e08f-44e9-d8d4-570bd1418317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10152, 22)\n",
            "(645, 22)\n",
            "(9507, 22)\n",
            "(408, 22)\n",
            "(93, 22)\n",
            "(29, 22)\n",
            "(10, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct_dt_tmp['InclusionCriteria'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rA6F1K5LuO-O",
        "outputId": "88265d51-1d28-47c4-b33f-cc149978ffdc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Age ≥ 18 years at the time of screening.|Eastern Cooperative Oncology Group performance status of ≤ 2.|Written informed consent obtained from the patient.|Histologically and cytologically documented Stage 3B-4 lung cancer (according to Version 8 of the International Association for the Study of Lung Cancer Staging system).|Patients with stage 1 to 3, who undergo radical therapy with disease free survival (DFS) >12 months.|Willingness and ability to comply with scheduled visits and other study procedures.||'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['InclusionCriteria'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "CuHh2c9QviM-",
        "outputId": "79d093a3-4228-4da5-a236-1dd8b2100631"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Histologically diagnosed with metastatic non-small cell lung cancer in 2018 | Initially treated with pertuzumab but relapsed | His performance status is ECOG 1 or KPS 90 | His blood and liver function analysis show normal | No other indications like HIV, HCV, HBV | No allergies | Life expectancy over 6 months | No mental disabilities.'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering 1\n",
        "CounVectoriser and TFIDF on the whole InclusionCriterias"
      ],
      "metadata": {
        "id": "IEiXw_LYWhke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python libs to manipulate dataframes and arrays\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# To get the word vectors, you need a word embedding model. Let’s download the FastText model using gensim’s downloader api.\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "\n",
        "# upgrade gensim if you can't import softcossim\n",
        "from gensim.matutils import softcossim \n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "\n",
        "def get_data():\n",
        "\n",
        "  # Download Clinical Trials data\n",
        "  print('Downloading Clinical Trials Data')\n",
        "  ct_dt = pd.read_csv(r'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_0.csv', sep=',', engine='python', encoding=\"utf-8\")\n",
        "  for btch in range(1, 4):\n",
        "      url = 'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_' +str(btch)+ '.csv'\n",
        "      tmp = pd.read_csv(url, sep=',', engine='python', encoding=\"ISO-8859-1\")\n",
        "      ct_dt = ct_dt.append(tmp, ignore_index=True)\n",
        "  ct_dt['AllLocation'] = ct_dt['LocationCity'].str.lower().map(str) + ' | ' + ct_dt['LocationState'].str.lower().map(str) + ' | ' + ct_dt['LocationCountry'].str.lower().map(str)\n",
        "  print('Clinical Trials Data: ',ct_dt.shape, '\\n')\n",
        "\n",
        "  # Download User input data\n",
        "  print('Downloading Test data')\n",
        "  test = pd.read_csv('https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/TestData.csv', sep=';', engine='python', encoding = \"utf-8\", skiprows=[0], names=['PatientID','ConditionOrDisease','Age','Gender','LocationCountry','TravelDistance','InclusionCriteria'])\n",
        "  print('Test Data: ', test.shape)\n",
        "\n",
        "  return ct_dt, test\n",
        "\n",
        "ct_dt, test = get_data()\n",
        "\n",
        "\n",
        "def data_processing(ct_dt):\n",
        "\n",
        "  print('Data dimensions before Filtering : ', ct_dt.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Age ###\n",
        "  print('Filtering by Age...')\n",
        "  tmp = ct_dt[ct_dt.iloc[:,13] <= test.iloc[:1,2][0]]               # compare numerics\n",
        "  tmp = tmp[tmp.iloc[:,13].str.find(test.iloc[:1,2][0][-5:]) != -1] # Detect the Year/Month\n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Gender ###\n",
        "  print('Filtering by Gender...')\n",
        "  tmp = tmp[(tmp.iloc[:,12] == test.iloc[:1,3][0]) | (tmp.iloc[:,12] == 'All')] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Travel Distance ###\n",
        "  print('Filtering by Travel Distance...')\n",
        "  tmp = tmp[tmp.iloc[:,20].str.find(test.iloc[:1,5][0].lower()) != -1] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  return tmp\n",
        "\n",
        "tmp = data_processing(ct_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5rG-pcTWjz3",
        "outputId": "8227acb3-c63b-410f-a8c3-ff038ebf288d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n",
            "Downloading Clinical Trials Data\n",
            "Clinical Trials Data:  (10152, 21) \n",
            "\n",
            "Downloading Test data\n",
            "Test Data:  (7, 7)\n",
            "Data dimensions before Filtering :  (10152, 21) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9517, 21) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9403, 21) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (645, 21) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#[1] Data\n",
        "ct_dt['InclusionCriteria'] = ct_dt['InclusionCriteria'].fillna(' ') # the whole dataset\n",
        "tmp['InclusionCriteria']   = tmp['InclusionCriteria'].fillna(' ')   # the subset of the data that we'll score\n",
        "test0                      = test.iloc[:1,6].fillna(' ')            # the user input\n",
        "\n",
        "'''\n",
        "TF-IDF is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words. \n",
        "We can then remove the words that are less important for analysis, hence making the model building less complex by reducing the input dimensions.\n",
        "TFIDF is based on the logic that words that are too abundant in a corpus and words that are too rare are both not statistically important for finding a pattern. \n",
        "The Logarithmic factor in tfidf mathematically penalizes the words that are too abundant or too rare in the corpus by giving them low tfidf scores.\n",
        "To train a model on the actual linguistic relationship of the words, there are two other word embedding techniques widely used in NLP, they are \"word2vec\" and \"Glove\". \n",
        "'''\n",
        "\n",
        "#[2] Instantiating Vectorization and Feature Engineerings methods\n",
        "cv  = CountVectorizer(encoding='utf-8', decode_error='ignore', strip_accents='ascii', lowercase=True, stop_words='english', analyzer='word', ngram_range=(2, 2), max_features=100000)\n",
        "tf = TfidfTransformer(use_idf=True)\n",
        "\n",
        "\n",
        "#[3] Processing the whole dataset\n",
        "cv_fitted_ctdt = cv.fit(ct_dt['InclusionCriteria'])\n",
        "cv_trans_ctdt  = cv_fitted_ctdt.transform(ct_dt['InclusionCriteria']) \n",
        "\n",
        "tf_fitted_ctdt = tf.fit(cv_trans_ctdt)\n",
        "tf_trans_ctdt  = tf_fitted_ctdt.transform(cv_trans_ctdt)\n",
        "\n",
        "\n",
        "#[4] Processing the subset of the data that we'll score \n",
        "cv_tmp = cv_fitted_ctdt.transform(tmp['InclusionCriteria'])\n",
        "tf_tmp = tf_fitted_ctdt.transform(cv_tmp)\n",
        "\n",
        "\n",
        "#[5] Processing the user input\n",
        "cv_test0 = cv_fitted_ctdt.transform(test0)\n",
        "tf_test0 = tf_fitted_ctdt.transform(cv_test0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJcozAeGaEPP",
        "outputId": "6af62b04-e9cb-4861-d469-3d30f2430a07"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.77 s, sys: 31.7 ms, total: 6.8 s\n",
            "Wall time: 7.02 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp['Similarity'] = pd.Series(cosine_similarity(tf_test0, tf_tmp)[0]).values\n",
        "\n",
        "ct_dt_tmp = ct_dt\n",
        "ct_dt_tmp['Similarity'] = 0\n",
        "print(ct_dt_tmp.shape)\n",
        "print(tmp.shape)\n",
        "\n",
        "ct_dt_tmp = ct_dt_tmp[~ct_dt_tmp['NCTId'].isin(tmp['NCTId'])]\n",
        "print(ct_dt_tmp.shape)\n",
        "ct_dt_tmp = ct_dt_tmp.append(tmp, ignore_index=True)\n",
        "\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.2].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.25].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.3].shape)\n",
        "\n",
        "ct_dt_tmp['Similarity'] = ct_dt_tmp['Similarity'].apply(lambda score: score if score>0 else 0) # if score>0.25\n",
        "ct_dt_tmp = ct_dt_tmp.sort_values(by=['Similarity'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsonrKddeL71",
        "outputId": "87323c7c-2ebe-4d49-9b76-2f8fa5bacd71"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10152, 22)\n",
            "(645, 22)\n",
            "(9507, 22)\n",
            "(520, 22)\n",
            "(0, 22)\n",
            "(0, 22)\n",
            "(0, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct_dt_tmp['InclusionCriteria'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "x0h8ihXKoGI7",
        "outputId": "3afb94c1-09c4-4d38-e80a-4f697f305ff8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Age ≥ 18 years at the time of screening.|Eastern Cooperative Oncology Group performance status of ≤ 2.|Written informed consent obtained from the patient.|Histologically and cytologically documented Stage 3B-4 lung cancer (according to Version 8 of the International Association for the Study of Lung Cancer Staging system).|Patients with stage 1 to 3, who undergo radical therapy with disease free survival (DFS) >12 months.|Willingness and ability to comply with scheduled visits and other study procedures.||'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*test0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETppMevJqBv6",
        "outputId": "479b8324-8f91-4f66-d80a-2c6476eb4a5d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Histologically diagnosed with metastatic non-small cell lung cancer in 2018 | Initially treated with pertuzumab but relapsed | His performance status is ECOG 1 or KPS 90 | His blood and liver function analysis show normal | No other indications like HIV, HCV, HBV | No allergies | Life expectancy over 6 months | No mental disabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering 2\n",
        "CountVectorizer and TFIDF on the filtred subset of the InclusionCriterias"
      ],
      "metadata": {
        "id": "2wqn7lKVraL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python libs to manipulate dataframes and arrays\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# To get the word vectors, you need a word embedding model. Let’s download the FastText model using gensim’s downloader api.\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "\n",
        "# upgrade gensim if you can't import softcossim\n",
        "from gensim.matutils import softcossim \n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "\n",
        "def get_data():\n",
        "\n",
        "  # Download Clinical Trials data\n",
        "  print('Downloading Clinical Trials Data')\n",
        "  ct_dt = pd.read_csv(r'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_0.csv', sep=',', engine='python', encoding=\"utf-8\")\n",
        "  for btch in range(1, 4):\n",
        "      url = 'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_' +str(btch)+ '.csv'\n",
        "      tmp = pd.read_csv(url, sep=',', engine='python', encoding=\"ISO-8859-1\")\n",
        "      ct_dt = ct_dt.append(tmp, ignore_index=True)\n",
        "  ct_dt['AllLocation'] = ct_dt['LocationCity'].str.lower().map(str) + ' | ' + ct_dt['LocationState'].str.lower().map(str) + ' | ' + ct_dt['LocationCountry'].str.lower().map(str)\n",
        "  print('Clinical Trials Data: ',ct_dt.shape, '\\n')\n",
        "\n",
        "  # Download User input data\n",
        "  print('Downloading Test data')\n",
        "  test = pd.read_csv('https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/TestData.csv', sep=';', engine='python', encoding = \"utf-8\", skiprows=[0], names=['PatientID','ConditionOrDisease','Age','Gender','LocationCountry','TravelDistance','InclusionCriteria'])\n",
        "  print('Test Data: ', test.shape)\n",
        "\n",
        "  return ct_dt, test\n",
        "\n",
        "ct_dt, test = get_data()\n",
        "\n",
        "\n",
        "def data_processing(ct_dt):\n",
        "\n",
        "  print('Data dimensions before Filtering : ', ct_dt.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Age ###\n",
        "  print('Filtering by Age...')\n",
        "  tmp = ct_dt[ct_dt.iloc[:,13] <= test.iloc[:1,2][0]]               # compare numerics\n",
        "  tmp = tmp[tmp.iloc[:,13].str.find(test.iloc[:1,2][0][-5:]) != -1] # Detect the Year/Month\n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Gender ###\n",
        "  print('Filtering by Gender...')\n",
        "  tmp = tmp[(tmp.iloc[:,12] == test.iloc[:1,3][0]) | (tmp.iloc[:,12] == 'All')] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Travel Distance ###\n",
        "  print('Filtering by Travel Distance...')\n",
        "  tmp = tmp[tmp.iloc[:,20].str.find(test.iloc[:1,5][0].lower()) != -1] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  return tmp\n",
        "\n",
        "tmp = data_processing(ct_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTPz23XqVg2",
        "outputId": "21a87fe8-c191-490c-e86e-1d9b12f0df22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n",
            "Downloading Clinical Trials Data\n",
            "Clinical Trials Data:  (10152, 21) \n",
            "\n",
            "Downloading Test data\n",
            "Test Data:  (7, 7)\n",
            "Data dimensions before Filtering :  (10152, 21) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9517, 21) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9403, 21) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (645, 21) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#[1] Data\n",
        "ct_dt['InclusionCriteria'] = ct_dt['InclusionCriteria'].fillna(' ') # the whole dataset\n",
        "tmp['InclusionCriteria']   = tmp['InclusionCriteria'].fillna(' ')   # the subset of the data that we'll score\n",
        "test0                      = test.iloc[:1,6].fillna(' ')            # the user input\n",
        "\n",
        "\n",
        "\n",
        "#[2] Instantiating Vectorization and Feature Engineerings methods\n",
        "cv  = CountVectorizer(encoding='utf-8', decode_error='ignore', strip_accents='ascii', lowercase=True, stop_words='english', analyzer='word', ngram_range=(2, 2), max_features=100000)\n",
        "tf = TfidfTransformer(use_idf=True)\n",
        "\n",
        "\n",
        "#[3] Processing the whole dataset\n",
        "cv_fitted_tmp = cv.fit(tmp['InclusionCriteria'])\n",
        "cv_trans_tmp  = cv_fitted_tmp.transform(tmp['InclusionCriteria']) \n",
        "\n",
        "tf_fitted_tmp = tf.fit(cv_trans_tmp)\n",
        "tf_trans_tmp  = tf_fitted_tmp.transform(cv_trans_tmp)\n",
        "\n",
        "\n",
        "#[4] Processing the user input\n",
        "cv_test0 = cv_fitted_tmp.transform(test0)\n",
        "tf_test0 = tf_fitted_tmp.transform(cv_test0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVt9WAZTrh80",
        "outputId": "35be6b82-5b40-4976-e817-f85d3a3a5a8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 725 ms, sys: 8.36 ms, total: 734 ms\n",
            "Wall time: 762 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp['Similarity'] = pd.Series(cosine_similarity(tf_test0, tf_trans_tmp)[0]).values\n",
        "\n",
        "ct_dt_tmp = ct_dt\n",
        "ct_dt_tmp['Similarity'] = 0\n",
        "print(ct_dt_tmp.shape)\n",
        "print(tmp.shape)\n",
        "\n",
        "ct_dt_tmp = ct_dt_tmp[~ct_dt_tmp['NCTId'].isin(tmp['NCTId'])]\n",
        "print(ct_dt_tmp.shape)\n",
        "ct_dt_tmp = ct_dt_tmp.append(tmp, ignore_index=True)\n",
        "\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.1].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.2].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.25].shape)\n",
        "print(ct_dt_tmp[ct_dt_tmp['Similarity']>0.3].shape)\n",
        "\n",
        "ct_dt_tmp['Similarity'] = ct_dt_tmp['Similarity'].apply(lambda score: score if score>0 else 0) # if score>0.25\n",
        "ct_dt_tmp = ct_dt_tmp.sort_values(by=['Similarity'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt14PTwVsETQ",
        "outputId": "b09a7b66-09ea-4c5d-a523-0b547240c7a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10152, 22)\n",
            "(645, 22)\n",
            "(9507, 22)\n",
            "(14, 22)\n",
            "(1, 22)\n",
            "(0, 22)\n",
            "(0, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct_dt_tmp['InclusionCriteria'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "AgNM8PszscFf",
        "outputId": "d8ce2a9e-f88a-4021-a02d-62e570a933ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Age ≥ 18 years at the time of screening.|Eastern Cooperative Oncology Group performance status of ≤ 2.|Written informed consent obtained from the patient.|Histologically and cytologically documented Stage 3B-4 lung cancer (according to Version 8 of the International Association for the Study of Lung Cancer Staging system).|Patients with stage 1 to 3, who undergo radical therapy with disease free survival (DFS) >12 months.|Willingness and ability to comply with scheduled visits and other study procedures.||'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct_dt_tmp['InclusionCriteria'][0]\n",
        "print(*test0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Sz7jEVso-t",
        "outputId": "637e31a5-a8df-4e6d-dba7-283b1c641eba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Histologically diagnosed with metastatic non-small cell lung cancer in 2018 | Initially treated with pertuzumab but relapsed | His performance status is ECOG 1 or KPS 90 | His blood and liver function analysis show normal | No other indications like HIV, HCV, HBV | No allergies | Life expectancy over 6 months | No mental disabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering 3\n",
        "Punctuation, Lemmatisation with NLTK\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html"
      ],
      "metadata": {
        "id": "XN6uUUtDwUSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IHpNLbbtwkrc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}