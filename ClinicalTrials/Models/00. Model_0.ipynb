{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0. Model_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNz7X4785W2JTp/LAEF5GJ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWFK/NLP-Semantic-Similarity/blob/main/ClinicalTrials/Models/00.%20Model_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives\n",
        "\n",
        "Get and process data, then apply Count Vectorizer followed by Cosine Similarity."
      ],
      "metadata": {
        "id": "PNEg4ZGnTPHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libs"
      ],
      "metadata": {
        "id": "cp5tsbvhTAnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DfZBQ26QS06V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8799f5d-be4e-4ea1-e23b-5768f3382537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# We'll use it to download final results\n",
        "from google.colab import files\n",
        "\n",
        "# Python libs to manipulate dataframes and arrays\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Accelerate processing\n",
        "from functools import lru_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "3ZkxAJS_TMVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "\n",
        "  # Download Clinical Trials data\n",
        "  print('Downloading Clinical Trials Data')\n",
        "  ct_dt = pd.read_csv(r'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_0.csv', sep=',', engine='python', encoding=\"utf-8\")\n",
        "  for btch in range(1, 4):\n",
        "      url = 'https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/Batches_' +str(btch)+ '.csv'\n",
        "      tmp = pd.read_csv(url, sep=',', engine='python', encoding=\"ISO-8859-1\")\n",
        "      ct_dt = ct_dt.append(tmp, ignore_index=True)\n",
        "  ct_dt['AllLocation'] = ct_dt['LocationCity'].str.lower().map(str) + ' | ' + ct_dt['LocationState'].str.lower().map(str) + ' | ' + ct_dt['LocationCountry'].str.lower().map(str)\n",
        "  print('Clinical Trials Data: ',ct_dt.shape, '\\n')\n",
        "\n",
        "  # Download User input data\n",
        "  print('Downloading Test data')\n",
        "  test = pd.read_csv('https://raw.githubusercontent.com/MWFK/NLP-Semantic-Similarity/main/ClinicalTrials/Data/TestData.csv', sep=';', engine='python', encoding = \"utf-8\", skiprows=[0], names=['PatientID','ConditionOrDisease','Age','Gender','LocationCountry','TravelDistance','InclusionCriteria'])\n",
        "  print('Test Data: ', test.shape)\n",
        "\n",
        "  return ct_dt, test\n",
        "\n",
        "# ctdt, test = get_data()"
      ],
      "metadata": {
        "id": "Z6rqL2IzTJpL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Processing"
      ],
      "metadata": {
        "id": "FxiZBc12Toft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip Leading and Trailing Space\n",
        "def cleansing(data):\n",
        "  cols = data.select_dtypes(['object']).columns\n",
        "  data[cols] = data[cols].apply(lambda x: x.str.strip().fillna(''))\n",
        "  return data"
      ],
      "metadata": {
        "id": "QhcBjZvNrDv0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_filtering(ct_dt, test):\n",
        "\n",
        "  print('Data dimensions before Filtering : ', ct_dt.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Age ###\n",
        "  print('Filtering by Age...')\n",
        "  tmp = ct_dt[ct_dt.iloc[:,13] <= test.iloc[0,2]]               # compare numerics\n",
        "  tmp = tmp[tmp.iloc[:,13].str.find(test.iloc[0,2][-5:]) != -1] # Detect the Year/Month\n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Gender ###\n",
        "  print('Filtering by Gender...')\n",
        "  tmp = tmp[(tmp.iloc[:,12] == test.iloc[0,3]) | (tmp.iloc[:,12] == 'All')] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  ### Filtering by Travel Distance ###\n",
        "  print('Filtering by Travel Distance...')\n",
        "  tmp = tmp[tmp.iloc[:,20].str.find(test.iloc[0,5].lower()) != -1] \n",
        "  print('Data dimensions: ', tmp.shape, '\\n')\n",
        "\n",
        "  return tmp\n",
        "\n",
        "# filtered = data_filtering(ctdt, test)"
      ],
      "metadata": {
        "id": "5MxUJCKCThPb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize the Data"
      ],
      "metadata": {
        "id": "LaIuEMM6Tx5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sources\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "# https://scikit-learn.org/stable/modules/feature_extraction.html\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "# The Lemmatizer uses nltk 'punkt' and 'wordnet'.\n",
        "@lru_cache(maxsize=10000)\n",
        "class LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "    def __call__(self, doc):\n",
        "        return [self.wnl.lemmatize(t.lower()) for t in word_tokenize(doc) if t.lower() not in stopwords] # Lemmatize words that are not stopwords, so in the countvectorizer it does not make a conflict with the stop word parameter"
      ],
      "metadata": {
        "id": "eqnJnTpVgYXr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorization(test, filtered, ctdt):\n",
        "\n",
        "  ctdt['InclusionCriteria'] = ctdt['InclusionCriteria'].fillna(' ')\n",
        "  filtered['InclusionCriteria']   = filtered['InclusionCriteria'].fillna(' ')\n",
        "\n",
        "  cv      = CountVectorizer(encoding='utf-8', decode_error='ignore', strip_accents='ascii', lowercase=True, tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(1, 2), max_features=50000)\n",
        "  cv_ctdt = cv.fit(ctdt['InclusionCriteria'])\n",
        "\n",
        "  cv_filtered = cv_ctdt.transform(filtered['InclusionCriteria'])\n",
        "\n",
        "  cv_test0    = cv_ctdt.transform(test.iloc[:1,6].fillna(' '))\n",
        "\n",
        "  return cv_test0, cv_filtered\n",
        "\n",
        "\n",
        "# filtered = data_processing(ctdt)\n",
        "# cv_test0, cv_filtered = vectorization(test.iloc[:1,], filtered, ctdt)\n",
        "# filtered['Similarity'] = pd.Series(cosine_similarity(cv_test0, cv_filtered)[0]).values"
      ],
      "metadata": {
        "id": "MI2X6OWYTr-t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "-ECddnVyUX1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results(cv_test0, cv_filtered, filtered, ctdt):\n",
        "\n",
        "  filtered['Similarity'] = pd.Series(cosine_similarity(cv_test0, cv_filtered)[0]).values\n",
        "\n",
        "  ctdt_filtered = ctdt\n",
        "  ctdt_filtered['Similarity'] = 0\n",
        "  print('Dataset shape: ', ctdt_filtered.shape)\n",
        "  print('Filtered Dataset shape: ', filtered.shape)\n",
        "\n",
        "  # Take off the existing NCTId from the whole dataset then add the filter data to \n",
        "  ctdt_filtered = ctdt_filtered[~ctdt_filtered['NCTId'].isin(filtered['NCTId'])]\n",
        "  ctdt_filtered = ctdt_filtered.append(filtered, ignore_index=True)\n",
        "\n",
        "  print('\\nScore > 0 ', ctdt_filtered[ctdt_filtered['Similarity']>0].shape)\n",
        "  print('Score > 0.05', ctdt_filtered[ctdt_filtered['Similarity']>0.05].shape)\n",
        "  print('Score > 0.10', ctdt_filtered[ctdt_filtered['Similarity']>0.1].shape)\n",
        "  print('Score > 0.15', ctdt_filtered[ctdt_filtered['Similarity']>0.15].shape)\n",
        "  print('Score > 0.20', ctdt_filtered[ctdt_filtered['Similarity']>0.2].shape)\n",
        "  print('Score > 0.25', ctdt_filtered[ctdt_filtered['Similarity']>0.25].shape)\n",
        "  print('Score > 0.30', ctdt_filtered[ctdt_filtered['Similarity']>0.3].shape)\n",
        "\n",
        "  ctdt_filtered['Similarity'] = ctdt_filtered['Similarity'].apply(lambda score: score if score>0.1 else 0) # if score>0.25\n",
        "  ctdt_filtered = ctdt_filtered.sort_values(by=['Similarity'], ascending=False)\n",
        "\n",
        "  return ctdt_filtered\n",
        "\n",
        "  #get_results(cv_test0, cv_filtered, filtered, ctdt).head(2)"
      ],
      "metadata": {
        "id": "RKDeR0KUUPzm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution Test"
      ],
      "metadata": {
        "id": "LTUdBYNXb_Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get The Clinical Trials Data, and the Test data\n",
        "# ctdt, test = get_data()\n",
        "\n",
        "# # Clean Data\n",
        "# ctdt = cleansing(ctdt)\n",
        "# test = cleansing(test)\n",
        "\n",
        "# # Filter the Clinical Trials Data based on the test data\n",
        "# filtered = data_filtering(ctdt, test.iloc[:1,])\n",
        "\n",
        "# # Vectorize the filtered data and the test data\n",
        "# cv_test0, cv_filtered = vectorization(test.iloc[:1,], filtered, ctdt)\n",
        "\n",
        "# # Get the final results and it's related stats\n",
        "# ctdt_filtered = get_results(cv_test0, cv_filtered, filtered, ctdt)\n",
        "# ctdt_filtered.head(2)"
      ],
      "metadata": {
        "id": "8Yc7adWYZikq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(*ctdt_filtered.iloc[:1,0])"
      ],
      "metadata": {
        "id": "5QOQ9NXV5yqT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting Results"
      ],
      "metadata": {
        "id": "6pgkDkE0Vgqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get The Clinical Trials Data, and the Test data\n",
        "ctdt, test = get_data()\n",
        "\n",
        "# Clean Data\n",
        "ctdt = cleansing(ctdt)\n",
        "test = cleansing(test)\n",
        "\n",
        "for index, row in test.iterrows():\n",
        "\n",
        "    #print(index, row['InclusionCriteria'])\n",
        "    print('\\n###################################')\n",
        "    print('Processing the user input: [', index,']')\n",
        "    print('###################################\\n')\n",
        "\n",
        "    # Filter the Clinical Trials Data based on the test data\n",
        "    filtered = data_filtering(ctdt, test.iloc[index:index+1,])\n",
        "\n",
        "    # Vectorize the filtered data and the test data\n",
        "    cv_test0, cv_filtered = vectorization(test.iloc[index:index+1,], filtered, ctdt)\n",
        "\n",
        "    # Get the final results and it's related stats\n",
        "    get_results(cv_test0, cv_filtered, filtered, ctdt).to_excel('/content/Patient_'+str(index)+'.xlsx', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOa7GWOdVjiN",
        "outputId": "aa655f44-6738-4781-d413-6602ce7d681f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Clinical Trials Data\n",
            "Clinical Trials Data:  (10152, 21) \n",
            "\n",
            "Downloading Test data\n",
            "Test Data:  (7, 7)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 0 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 21) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9517, 21) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9403, 21) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (645, 21) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (645, 22)\n",
            "\n",
            "Score > 0  (626, 22)\n",
            "Score > 0.05 (549, 22)\n",
            "Score > 0.10 (351, 22)\n",
            "Score > 0.15 (94, 22)\n",
            "Score > 0.20 (6, 22)\n",
            "Score > 0.25 (0, 22)\n",
            "Score > 0.30 (0, 22)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 1 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 22) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9173, 22) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9138, 22) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (372, 22) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (372, 22)\n",
            "\n",
            "Score > 0  (367, 22)\n",
            "Score > 0.05 (301, 22)\n",
            "Score > 0.10 (118, 22)\n",
            "Score > 0.15 (12, 22)\n",
            "Score > 0.20 (0, 22)\n",
            "Score > 0.25 (0, 22)\n",
            "Score > 0.30 (0, 22)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 2 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 22) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9650, 22) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9535, 22) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (68, 22) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (68, 22)\n",
            "\n",
            "Score > 0  (67, 22)\n",
            "Score > 0.05 (25, 22)\n",
            "Score > 0.10 (3, 22)\n",
            "Score > 0.15 (0, 22)\n",
            "Score > 0.20 (0, 22)\n",
            "Score > 0.25 (0, 22)\n",
            "Score > 0.30 (0, 22)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 3 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 22) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (105, 22) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (104, 22) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (23, 22) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (23, 22)\n",
            "\n",
            "Score > 0  (22, 22)\n",
            "Score > 0.05 (15, 22)\n",
            "Score > 0.10 (8, 22)\n",
            "Score > 0.15 (3, 22)\n",
            "Score > 0.20 (0, 22)\n",
            "Score > 0.25 (0, 22)\n",
            "Score > 0.30 (0, 22)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 4 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 22) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9565, 22) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9520, 22) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (9520, 22) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (9520, 22)\n",
            "\n",
            "Score > 0  (9149, 22)\n",
            "Score > 0.05 (7480, 22)\n",
            "Score > 0.10 (2696, 22)\n",
            "Score > 0.15 (192, 22)\n",
            "Score > 0.20 (11, 22)\n",
            "Score > 0.25 (2, 22)\n",
            "Score > 0.30 (0, 22)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 5 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 22) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9565, 22) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9451, 22) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (471, 22) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (471, 22)\n",
            "\n",
            "Score > 0  (464, 22)\n",
            "Score > 0.05 (436, 22)\n",
            "Score > 0.10 (351, 22)\n",
            "Score > 0.15 (149, 22)\n",
            "Score > 0.20 (4, 22)\n",
            "Score > 0.25 (0, 22)\n",
            "Score > 0.30 (0, 22)\n",
            "\n",
            "###################################\n",
            "Processing the user input: [ 6 ]\n",
            "###################################\n",
            "\n",
            "Data dimensions before Filtering :  (10152, 22) \n",
            "\n",
            "Filtering by Age...\n",
            "Data dimensions:  (9212, 22) \n",
            "\n",
            "Filtering by Gender...\n",
            "Data dimensions:  (9175, 22) \n",
            "\n",
            "Filtering by Travel Distance...\n",
            "Data dimensions:  (9175, 22) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (10152, 22)\n",
            "Filtered Dataset shape:  (9175, 22)\n",
            "\n",
            "Score > 0  (8930, 22)\n",
            "Score > 0.05 (8108, 22)\n",
            "Score > 0.10 (6032, 22)\n",
            "Score > 0.15 (2337, 22)\n",
            "Score > 0.20 (138, 22)\n",
            "Score > 0.25 (4, 22)\n",
            "Score > 0.30 (1, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading results"
      ],
      "metadata": {
        "id": "wKd9HWw98qOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(7):\n",
        "  files.download('Patient_'+str(index)+'.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZTuXHfsD8UVj",
        "outputId": "f0663ccf-7911-4f6d-d3bd-7b01a1b9a2a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_13816466-742d-4484-9cdd-cae10ec3bc05\", \"Patient_0.xlsx\", 18126526)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0ca2a779-5a25-4c94-8267-2f2b4c2f52f3\", \"Patient_1.xlsx\", 18124246)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9401d6ac-4a45-4b22-bc89-d1c95506ac38\", \"Patient_2.xlsx\", 18182778)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5027a231-9fa7-431a-956b-09564b00c027\", \"Patient_3.xlsx\", 18192188)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0ef8f359-d937-4130-af06-5800149f8209\", \"Patient_4.xlsx\", 18222208)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b5e1ab6d-23be-414b-bce8-9a420009db72\", \"Patient_5.xlsx\", 18131334)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0b7271a8-844a-41a1-a4b1-74bfdc36dc6e\", \"Patient_6.xlsx\", 18317772)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}